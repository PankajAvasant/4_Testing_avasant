{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "OPENAI_API_KEY = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\testing\\venv310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "from llama_index import (\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index import VectorStoreIndex, StorageContext\n",
    "from llama_index.indices.multi_modal.base import MultiModalVectorStoreIndex\n",
    "\n",
    "# Create a local Qdrant vector store\n",
    "client = qdrant_client.QdrantClient(path=\"qdrant_db\")\n",
    "\n",
    "text_store = QdrantVectorStore(\n",
    "    client=client, collection_name=\"text_collection\"\n",
    ")\n",
    "image_store = QdrantVectorStore(\n",
    "    client=client, collection_name=\"image_collection\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=text_store, image_store=image_store\n",
    ")\n",
    "\n",
    "# Create the MultiModal index\n",
    "documents = SimpleDirectoryReader(\"./ava_input_images/\").load_data()\n",
    "index = MultiModalVectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ploting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "def plot_images(image_paths):\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for img_path in image_paths:\n",
    "        if os.path.isfile(img_path):\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            plt.subplot(2, 3, images_shown + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            images_shown += 1\n",
    "            if images_shown >= 9:\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quiery image : \n",
    "\n",
    "\n",
    "\n",
    "way:01: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The business applications expenses as an average percentage of total IT spending in the retail sector is 8.4%.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "\n",
    "openai_mm_llm = OpenAIMultiModal(\n",
    "    model=\"gpt-4-vision-preview\", api_key=OPENAI_API_KEY, max_new_tokens=1500\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    multi_modal_llm=openai_mm_llm,\n",
    ")\n",
    "# query_str = \"can you please tell me the companies with their related section\"\n",
    "query_str = \"give me the business applications expenses as Average Percentage of total IT spending: Retail\"\n",
    "response = query_engine.query(query_str)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "way : 02: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images provided are two different types of charts.\n",
      "\n",
      "The first image appears to be a circular diagram, often referred to as a radar chart or spider chart, which is used to display multivariate data in the form of a two-dimensional chart. It shows various companies categorized into different levels of \"Practice maturity\" with labels such as \"Leaders,\" \"Innovators,\" \"Challengers,\" and \"Disruptors.\" Companies are placed at different points within these categories, suggesting a ranking or assessment of their capabilities or maturity in a certain context.\n",
      "\n",
      "The second image is a bar graph titled \"Total IT Spending as Average Percentage of Budget Categories: Retail.\" It shows different categories of IT spending as a percentage of the total budget. The categories include IT personnel, business applications, data center/hardware, network infrastructure, IT facilities/floor space, and several others. Each category has a corresponding bar indicating the percentage of the budget it consumes. The source of the data is cited as \"Avasant Research: Computer Economics, 2023.\"\n",
      "\n",
      "Please note that I cannot provide specific details such as company names or exact percentages from the charts.\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "# from llama_index.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# qa_tmpl_str = (\n",
    "#     \"Given the images provided, \"\n",
    "#     \"answer the query.\\n\"\n",
    "#     \"Query: {query_str}\\n\"\n",
    "#     \"Answer: \"\n",
    "# )\n",
    "\n",
    "# qa_tmpl = PromptTemplate(qa_tmpl_str)\n",
    "\n",
    "\n",
    "# openai_mm_llm = OpenAIMultiModal(\n",
    "#     model=\"gpt-4-vision-preview\", api_key=OPENAI_API_KEY, max_new_tokens=1500\n",
    "# )\n",
    "\n",
    "# query_engine = index.as_query_engine(\n",
    "#     multi_modal_llm=openai_mm_llm, image_qa_template=qa_tmpl\n",
    "# )\n",
    "\n",
    "# query_str = \"give me the summary of the image\"\n",
    "# response = query_engine.image_query('./ava_input_images/pankaj.png', query_str)\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but the images provided do not contain the specific information regarding IT personnel expenses as an average percentage of total IT spending in the retail sector. The second image shows a chart with various budget categories as a percentage of total IT spending, but it does not specify that the data is for the retail sector. If you have an image or data that specifically addresses IT personnel expenses in the retail sector, please provide it, and I'll be happy to help you with the information you're looking for.\n"
     ]
    }
   ],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "way : 03: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"can you please tell me the companies with their related section\"\n",
    "# generate  retrieval results\n",
    "retriever = index.as_retriever(similarity_top_k=10, image_similarity_top_k=10)\n",
    "retrieval_results = retriever.retrieve(test_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 2803e0bd-b7fb-4ee7-bcb9-00f15cd88194\n",
      "Text:\n",
      "Score:  0.206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.response.notebook_utils import display_source_node\n",
    "from llama_index.schema import ImageNode\n",
    "\n",
    "retrieved_image = []\n",
    "for res_node in retrieval_results:\n",
    "    print(res_node)\n",
    "    if isinstance(res_node.node, ImageNode):\n",
    "        retrieved_image.append(res_node.node.metadata[\"file_path\"])\n",
    "    else:\n",
    "        display_source_node(res_node, source_length=200)\n",
    "\n",
    "# plot_images(retrieved_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
